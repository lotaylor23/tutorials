{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941b1260",
   "metadata": {},
   "source": [
    "# ISCB-Africa ASBCB 2025\n",
    "\n",
    "## Lagoon Beach Hotel & Conference Center, Cape Town, South Africa\n",
    "\n",
    "**Date of the session:** April 10, 2025\n",
    "\n",
    "**Instructor(s)/Affiliation(s):** Loni Taylor, Meharry Medical College, Nashville, TN, USA. Bishnu Sarker, Meharry Medical College, Nashville, TN, USA. Animesh Acharjee, University of Birmingham, UK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce5dde",
   "metadata": {},
   "source": [
    "## **Non-negative Matrix Factorization (NMF) for Multiomics Data Integration**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daedc772",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "This section will dive deeper into Non-negative Matrix Factorization (NMF), explaining how it can be used to decompose complex multiomics datasets into meaningful components. NMF‚Äôs role in identifying latent biological factors and reducing the complexity of data will be discussed in the context of multiomics.\n",
    "\n",
    "#### Topics:\n",
    "\n",
    "+ Principles of NMF and its applications in biological data\n",
    "+ How NMF helps in dimensionality reduction and feature extraction\n",
    "+ Sample demonstration using NMF in omics data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeacdd3",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization (NMF):\n",
    "\n",
    "NMF is a matrix factorization technique that helps uncover hidden patterns in complex datasets by decomposing data into non-negative components. NMF decomposes a non-negative matrix into two non-negative matrices‚Äîone representing the relationship between samples and the latent components, and the other representing the relationship between the latent components and the original features.\n",
    "\n",
    "It is particularly useful in multiomics, where it can identify latent factors that represent biological processes shared across different layers of omic data. By applying NMF, we can reduce the dimensionality of multi-omics data, making it easier to analyze and visualize complex biological relationships. In the context of multiomics data, NMF can uncover shared patterns across different omics layers, reducing the complexity of the data and enabling further analysis such as clustering, classification, and feature extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f232e",
   "metadata": {},
   "source": [
    "### Key Characteristics of NMF:\n",
    "\n",
    "**1. Unsupervised Learning:** NMF is unsupervised because it doesn't require labeled data. It seeks to find hidden patterns or structures in the data based on the data's intrinsic properties.\n",
    "\n",
    "**2. Factorization:** NMF works by factorizing a non-negative matrix ùëâ into two smaller non-negative matrices ùëä and ùêª, such that:\n",
    "\n",
    "                        ùëâ ‚âà ùëä √ó ùêª\n",
    "\n",
    "+ ùëâ is the original data matrix (for example, gene expression values or document-term matrix).\n",
    "\n",
    "+ ùëä contains the \"basis\" or \"components,\" often interpreted as the features or patterns.\n",
    "\n",
    "+ ùêª contains the \"coefficients\" or \"activations,\" showing how strongly each component is present in the original data.\n",
    "\n",
    "**3. Non-Negativity Constraint:** The key feature of NMF is that it enforces non-negative values in the factorization. This is useful in biological data or image processing, where negative values may not make sense or may not have an interpretable meaning.\n",
    "\n",
    "**4. Dimensionality Reduction:** NMF is often used for reducing the dimensionality of the data while maintaining interpretability. The lower-dimensional representations (in ùëä and ùêª) can reveal latent patterns or clusters in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87416746",
   "metadata": {},
   "source": [
    "### Applications:\n",
    "\n",
    "+ Gene Expression Data: NMF is commonly used to uncover hidden patterns in gene expression data, identifying gene signatures or latent biological processes.\n",
    "\n",
    "+ Text Mining: In natural language processing, NMF can be applied to decompose document-term matrices to uncover topics (similar to Latent Dirichlet Allocation, LDA).\n",
    "\n",
    "+ Image Processing: NMF is also used for image compression and feature extraction, where the matrix could represent pixel intensities.\n",
    "\n",
    "+ Multiomics Integration: NMF can be applied to integrate and uncover common features in multiple omics layers (e.g., genomics, transcriptomics, and proteomics)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cad34b",
   "metadata": {},
   "source": [
    "The following remainder of the notebook demonstrates how to implement NMF for integrating multiomics data, such as RNA expression, methylation, and protein expression data.\n",
    "Download and follow this code notebook to see a simple process of integrating and analyzing multiomics data in python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fec17b",
   "metadata": {},
   "source": [
    "## Implementing Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44284d89",
   "metadata": {},
   "source": [
    "We begin with our basic library imports. Pandas, numpy and scikit-learn for our data analysis, scientific computing, and machine learning needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b617a3",
   "metadata": {},
   "source": [
    "#### Pandas\n",
    "\n",
    "+ Purpose: Data manipulation and analysis.\n",
    "\n",
    "+ Key Features:\n",
    "\n",
    "    + Provides DataFrame and Series objects for handling data.\n",
    "\n",
    "    + Easy handling of missing data.\n",
    "\n",
    "    + Supports merging, grouping, and reshaping data.\n",
    "\n",
    "    + Ideal for data cleaning, transformation, and exploration.\n",
    "\n",
    "+ Common Use: Loading data from various sources (CSV, Excel, SQL), data wrangling (cleaning, reshaping, etc.), and exploratory data analysis (EDA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65943d4a",
   "metadata": {},
   "source": [
    "#### NumPy\n",
    "+ Purpose: Numerical computations and array manipulation.\n",
    "\n",
    "+ Key Features:\n",
    "\n",
    "    + Provides support for multi-dimensional arrays and matrices.\n",
    "\n",
    "    + Fast array operations (vectorized operations).\n",
    "\n",
    "    + Supports linear algebra, random sampling, and Fourier transforms.\n",
    "\n",
    "+ Common Use: High-performance operations on large arrays or matrices, scientific computing, and numerical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1999c",
   "metadata": {},
   "source": [
    "#### Scikit-learn\n",
    "+ Purpose: Machine learning.\n",
    "\n",
    "+ Key Features:\n",
    "\n",
    "    + A library for supervised and unsupervised learning.\n",
    "\n",
    "    + Provides tools for model training, evaluation, and cross-validation.\n",
    "\n",
    "    + Supports a wide range of algorithms, including classification, regression, clustering, and dimensionality reduction.\n",
    "\n",
    "    + Includes utilities for preprocessing, such as scaling, encoding, and splitting data.\n",
    "\n",
    "+ Common Use: Building and evaluating machine learning models, performing tasks like classification, regression, clustering, and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd427c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccbbe35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample multiomics data (replace with your actual data/filepath)\n",
    "# Each row represents a gene, and each column represents a sample\n",
    "# Data should be non-negative\n",
    "\n",
    "data = pd.read_csv('filepath/CLL_data_mRNA.csv')\n",
    "data2 = pd.read_csv('filepath/CLL_data_Methylation.csv')\n",
    "#data_rna = pd.DataFrame(np.random.rand(136, 50), index=['gene_{}'.format(i) for i in range(136)])\n",
    "data_rna = pd.DataFrame(data, index=['gene_{}'.format(i) for i in range(136)])\n",
    "#data_methylation = pd.DataFrame(np.random.rand(136, 50), index=['gene_{}'.format(i) for i in range(136)])\n",
    "data_methylation = pd.DataFrame(data2, index=['gene_{}'.format(i) for i in range(136)])\n",
    "data_protein = pd.DataFrame(np.random.rand(136, 50), index=['gene_{}'.format(i) for i in range(136)])\n",
    "#data_protein = pd.DataFrame(data, index=['gene_{}'.format(i) for i in range(len(data.columns))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c57a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###potential nans can be dropped before here:\n",
    "# Drop columns with any NaN values\n",
    "data_rna = data_rna.dropna(axis=1)\n",
    "data_methylation = data_methylation.dropna(axis=1)\n",
    "data_protein = data_protein.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a40b7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine multiomics data\n",
    "data_combined = pd.concat([data_rna, data_methylation, data_protein], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf542da",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "<br>\n",
    "Data Preparation:\n",
    "<br>\n",
    "The example data represents multi-omics data for RNA expression, methylation, and protein levels. These datasets are combined into a single matrix (data_combined), where rows represent genes and columns represent samples. Replace the sample data with your actual multiomics data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bb4529",
   "metadata": {},
   "source": [
    "Normalization:<br>\n",
    "Since NMF requires non-negative values, it's crucial to scale the data. We use MinMaxScaler to normalize the data within the range [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afc4e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data_combined)\n",
    "data_normalized = pd.DataFrame(data_normalized, index=data_combined.index, columns=data_combined.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a5003",
   "metadata": {},
   "source": [
    "Applying NMF:<br>\n",
    "The NMF algorithm is applied with the specified number of components (in this case, 10). The model decomposes the normalized data matrix into two non-negative matrices: \n",
    "+ W (sample-component matrix)<br> \n",
    "and\n",
    "+ H (component-feature matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618d9da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you see a similar message to this you can just increase the iterations: _nmf.py:1665: ConvergenceWarning: Maximum number of iterations 500 reached. Increase it to improve convergence. warnings.warn"
     ]
    }
   ],
   "source": [
    "# Apply NMF\n",
    "n_components = 10  # Number of components to extract\n",
    "nmf = NMF(n_components=n_components, init='nndsvda', random_state=0, max_iter=500)\n",
    "W = nmf.fit_transform(data_normalized)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f667c90",
   "metadata": {},
   "source": [
    "W captures the association between samples and NMF components (latent factors), while H captures the contribution of each original feature to each NMF component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7282581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for W and H\n",
    "W_df = pd.DataFrame(W, index=data_normalized.index, columns=['NMF_{}'.format(i) for i in range(n_components)])\n",
    "H_df = pd.DataFrame(H, index=['NMF_{}'.format(i) for i in range(n_components)], columns=data_normalized.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0adf8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W (Sample-component matrix):\n",
      "           NMF_0     NMF_1     NMF_2     NMF_3     NMF_4     NMF_5     NMF_6  \\\n",
      "gene_0  0.018561  0.000000  0.071710  0.074608  0.030406  0.000000  0.073465   \n",
      "gene_1  0.010157  0.001872  0.080459  0.103289  0.101455  0.000000  0.074791   \n",
      "gene_2  0.009635  0.002250  0.086954  0.079768  0.015968  0.101549  0.062943   \n",
      "gene_3  0.009095  0.001158  0.103489  0.000000  0.290887  0.138927  0.000000   \n",
      "gene_4  0.005647  0.000853  0.149064  0.089072  0.128870  0.067688  0.136676   \n",
      "\n",
      "           NMF_7     NMF_8     NMF_9  \n",
      "gene_0  0.435539  0.234751  0.108511  \n",
      "gene_1  0.186611  0.051346  0.042895  \n",
      "gene_2  0.013761  0.000000  0.360593  \n",
      "gene_3  0.146690  0.404938  0.123772  \n",
      "gene_4  0.000000  0.170508  0.000000  \n",
      "\n",
      "H (Component-feature matrix):\n",
      "             0          1         2          3         4          5   \\\n",
      "NMF_0  9.080151   0.000000  0.000000   0.000000  0.000000   0.000000   \n",
      "NMF_1  5.832292  32.436065  0.000000  22.605456  3.197621  55.064605   \n",
      "NMF_2  1.426999   0.729887  1.392062   1.429244  2.367231   4.633690   \n",
      "NMF_3  0.007482   0.000000  0.818949   2.235459  0.000000   1.103992   \n",
      "NMF_4  1.340099   0.779163  0.300880   0.451536  0.000000   0.000000   \n",
      "\n",
      "              6         7          8         9   ...         40         41  \\\n",
      "NMF_0   0.000000  0.704039  10.820830  0.000000  ...   0.000000   4.686491   \n",
      "NMF_1  75.336558  0.000000   0.000000  0.000000  ...  79.179383  15.510365   \n",
      "NMF_2   0.866938  1.448899   0.188725  0.646973  ...   0.000000   0.000000   \n",
      "NMF_3   3.932294  0.897492   0.850650  3.043414  ...   0.083272   0.000000   \n",
      "NMF_4   0.000000  2.526752   0.648244  0.000000  ...   0.000000   0.180079   \n",
      "\n",
      "             42         43         44         45         46        47  \\\n",
      "NMF_0  8.494155  10.783739  15.264663   0.000000   0.000000  4.819368   \n",
      "NMF_1  2.872665   4.025984   0.040735  14.119543  29.833338  0.000000   \n",
      "NMF_2  0.000000   1.571705   0.921242   0.000000   0.000000  0.000000   \n",
      "NMF_3  0.696217   1.157814   3.557771   2.159968   1.739142  2.634916   \n",
      "NMF_4  1.431897   0.030367   0.211389   1.729980   1.448975  0.320646   \n",
      "\n",
      "              48         49  \n",
      "NMF_0   0.000000   6.956793  \n",
      "NMF_1  68.018119  16.216423  \n",
      "NMF_2   0.000000   1.098232  \n",
      "NMF_3   2.089715   0.274763  \n",
      "NMF_4   0.409102   0.000000  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"W (Sample-component matrix):\")\n",
    "print(W_df.head())\n",
    "print(\"\\nH (Component-feature matrix):\")\n",
    "print(H_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9514b",
   "metadata": {},
   "source": [
    "Results Interpretation:<br>\n",
    "+ The W_df matrix shows how each sample relates to the underlying NMF components.\n",
    "+ The H_df matrix shows the importance of each original feature (e.g., genes, metabolites, proteins) in constructing each NMF component.\n",
    "\n",
    "These decomposed matrices (W and H) can be used for further analysis like clustering, identifying latent biological factors, or associating with phenotypic data such as disease status or treatment response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7dc13",
   "metadata": {},
   "source": [
    "#### Potential Use Cases for NMF in Multiomics Data:\n",
    "+ Dimensionality Reduction: Simplify complex multiomics datasets by focusing on the most important components.\n",
    "+ Pattern Discovery: Uncover hidden biological patterns across multiple omic layers, such as common pathways or gene-metabolite interactions.\n",
    "+ Feature Extraction: Identify key features (genes, proteins, metabolites) that drive biological processes or disease mechanisms.\n",
    "\n",
    "By using NMF, we can achieve a more integrative understanding of biological data, ultimately paving the way for improved disease classification, biomarker discovery, and drug response prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b193374",
   "metadata": {},
   "source": [
    "## Using_NMF_for_Biomarker_Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f0458",
   "metadata": {},
   "source": [
    "Building upon the previous section, this part will show how NMF can be applied to biomarker discovery. The audience will learn how to use NMF for identifying potential biomarkers that can be used for disease diagnosis, prognosis, or therapeutic targeting.\n",
    "\n",
    "### Topics:\n",
    "\n",
    "+ Biomarker discovery and its importance in precision medicine\n",
    "\n",
    "+ Practical applications of NMF in biomarker identification\n",
    "\n",
    "+ Hands-on example: Using NMF for identifying biomarkers in multiomics data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bb8f1",
   "metadata": {},
   "source": [
    "1. **What Are Biomarkers?**\n",
    "    + Definition: Biomarkers are measurable indicators of a biological state or condition‚Äîsuch as specific genes, proteins, or metabolites‚Äîthat can be used to detect or monitor diseases, predict treatment response, or classify disease subtypes.\n",
    "\n",
    "    + Examples:\n",
    "\n",
    "        + HER2 expression in breast cancer\n",
    "\n",
    "        + PSA levels in prostate cancer\n",
    "\n",
    "        + Blood glucose levels as a biomarker for diabetes\n",
    "\n",
    "\n",
    "2. **The Role of Multiomics in Biomarker Discovery**\n",
    "    + Multiomics data provide a comprehensive view of the molecular landscape, enabling the discovery of biomarkers not just at the gene level, but also at the transcript, protein, and metabolite levels.\n",
    "\n",
    "    + By integrating these data layers, researchers can identify multi-modal biomarkers‚Äîcombinations of omics features that jointly provide more predictive power than any single omic alone.\n",
    "\n",
    "\n",
    "3. **Why Use NMF for Biomarker Discovery?**\n",
    "    + Pattern Discovery: NMF excels at discovering co-expressed or co-regulated feature groups by breaking down complex data into additive parts, which can highlight biologically relevant patterns.\n",
    "\n",
    "    + Interpretability: Unlike many machine learning methods, NMF produces interpretable, sparse factors‚Äîeach component can be associated with a specific biological process or sample subtype.\n",
    "\n",
    "    + Feature Selection: The learned components from NMF can be analyzed to select features (e.g., genes or proteins) that contribute most to distinguishing disease vs. healthy samples, or to specific subtypes of a condition.\n",
    "\n",
    "\n",
    "4. **Step-by-Step: Applying NMF to Identify Biomarkers (this was done in our code example earlier)**\n",
    "    + Preprocessing:\n",
    "        + Normalize omics data (e.g., gene expression matrix)\n",
    "        + Filter low-variance features to reduce noise\n",
    "\n",
    "    + Apply NMF:\n",
    "        + Decompose the data matrix into two non-negative matrices: ùëä (feature matrix) and ùêª (sample matrix)\n",
    "        + Choose number of components (k), which might represent biological processes or patient subtypes\n",
    "\n",
    "    + Interpret Components:\n",
    "        + Analyze ùëä: Identify top contributing genes/proteins/metabolites for each component\n",
    "        + Analyze ùêª: Cluster samples based on their component profiles\n",
    "\n",
    "    + Biomarker Selection:\n",
    "        + Extract top-ranked features (e.g., top genes per component) as candidate biomarkers\n",
    "        + Validate them using external datasets or functional annotation databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998e795",
   "metadata": {},
   "source": [
    "### Demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9be86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming H_df from the first code is used for biomarker discovery\n",
    "# H_df is the component-feature matrix (rows = components, columns = features)\n",
    "\n",
    "# Function to identify top biomarkers for each NMF component\n",
    "def discover_biomarkers(H_df, top_n=10):\n",
    "    biomarkers = {}\n",
    "    \n",
    "    # Loop through each component and find the top features\n",
    "    for component in H_df.index:\n",
    "        # Sort the features by the weight (importance) in descending order\n",
    "        sorted_features = H_df.loc[component].sort_values(ascending=False)\n",
    "        \n",
    "        # Select the top 'n' biomarkers for this component\n",
    "        top_biomarkers = sorted_features.head(top_n)\n",
    "        \n",
    "        biomarkers[component] = top_biomarkers\n",
    "        \n",
    "    return biomarkers\n",
    "\n",
    "# Discover top biomarkers for each component\n",
    "top_biomarkers = discover_biomarkers(H_df, top_n=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71558e8b",
   "metadata": {},
   "source": [
    "Case Study: Using omics data from cancer patients, NMF identified the top biomarkers.\n",
    "\n",
    "Biomarker Discovery: The function *discover_biomarkers* processes the H_df matrix, which has the weights of each feature (gene, protein, etc.) for each NMF component. By sorting the weights for each component, we can identify the features most associated with that component.\n",
    "\n",
    "Top Biomarkers: For each NMF component, we select the top n features (genes, proteins) that have the highest weights. These are considered as the biomarkers for the corresponding component.\n",
    "\n",
    "Output: The top biomarkers for each component are printed. These are the features most strongly associated with each identified latent factor.\n",
    "\n",
    "These genes can then become candidate biomarkers for use in a prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4a8fe1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component NMF_0 - Top Biomarkers:\n",
      "31    18.698089\n",
      "25    17.675052\n",
      "14    16.417682\n",
      "20    15.605661\n",
      "44    15.264663\n",
      "34    13.821380\n",
      "35    11.587315\n",
      "10    11.498126\n",
      "8     10.820830\n",
      "43    10.783739\n",
      "Name: NMF_0, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_1 - Top Biomarkers:\n",
      "40    79.179383\n",
      "14    76.842831\n",
      "22    76.084987\n",
      "6     75.336558\n",
      "13    68.157619\n",
      "48    68.018119\n",
      "34    64.137355\n",
      "39    56.616922\n",
      "26    55.756656\n",
      "21    55.441853\n",
      "Name: NMF_1, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_2 - Top Biomarkers:\n",
      "5     4.633690\n",
      "4     2.367231\n",
      "30    2.209117\n",
      "32    2.055639\n",
      "37    2.013619\n",
      "20    1.987522\n",
      "39    1.666948\n",
      "33    1.659968\n",
      "43    1.571705\n",
      "23    1.521520\n",
      "Name: NMF_2, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_3 - Top Biomarkers:\n",
      "16    6.320379\n",
      "6     3.932294\n",
      "44    3.557771\n",
      "9     3.043414\n",
      "12    2.958299\n",
      "47    2.634916\n",
      "17    2.389752\n",
      "3     2.235459\n",
      "45    2.159968\n",
      "31    2.141935\n",
      "Name: NMF_3, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_4 - Top Biomarkers:\n",
      "7     2.526752\n",
      "38    2.225240\n",
      "28    1.847374\n",
      "45    1.729980\n",
      "32    1.537031\n",
      "46    1.448975\n",
      "20    1.437902\n",
      "42    1.431897\n",
      "26    1.381371\n",
      "0     1.340099\n",
      "Name: NMF_4, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_5 - Top Biomarkers:\n",
      "24    2.141912\n",
      "12    1.996615\n",
      "49    1.674319\n",
      "1     1.488621\n",
      "26    1.288945\n",
      "25    1.033683\n",
      "45    1.032654\n",
      "33    1.000818\n",
      "9     0.855939\n",
      "41    0.790059\n",
      "Name: NMF_5, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_6 - Top Biomarkers:\n",
      "13    2.386510\n",
      "15    1.495423\n",
      "28    1.466201\n",
      "35    1.296857\n",
      "19    1.226299\n",
      "46    1.124531\n",
      "1     0.992798\n",
      "25    0.983284\n",
      "47    0.982560\n",
      "44    0.964367\n",
      "Name: NMF_6, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_7 - Top Biomarkers:\n",
      "4     1.216192\n",
      "27    1.100130\n",
      "40    1.012954\n",
      "41    0.898951\n",
      "33    0.859457\n",
      "11    0.854940\n",
      "47    0.717392\n",
      "39    0.567515\n",
      "38    0.537068\n",
      "48    0.534604\n",
      "Name: NMF_7, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_8 - Top Biomarkers:\n",
      "43    1.050689\n",
      "27    0.859779\n",
      "39    0.678221\n",
      "46    0.664432\n",
      "41    0.647931\n",
      "29    0.599485\n",
      "36    0.595668\n",
      "2     0.578583\n",
      "8     0.576177\n",
      "0     0.567634\n",
      "Name: NMF_8, dtype: float64\n",
      "\n",
      "\n",
      "Component NMF_9 - Top Biomarkers:\n",
      "42    1.130510\n",
      "37    0.907395\n",
      "18    0.900130\n",
      "29    0.791506\n",
      "4     0.672017\n",
      "15    0.639690\n",
      "34    0.589641\n",
      "3     0.538905\n",
      "48    0.532662\n",
      "30    0.458995\n",
      "Name: NMF_9, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top biomarkers for each component\n",
    "for component, biomarkers_list in top_biomarkers.items():\n",
    "    print(f\"Component {component} - Top Biomarkers:\")\n",
    "    print(biomarkers_list)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb798d95",
   "metadata": {},
   "source": [
    "#### Applying Machine Learning for Multiomics Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4764d6",
   "metadata": {},
   "source": [
    "Next, we will implement predictive models based on our results.  This will be done using a Random Forest Classifier over our data set.\n",
    "\n",
    "We will use the W_df matrix (which is the output from NMF representing the transformed features in the component space).\n",
    "\n",
    "For this demonstration we assume that y (the diagnosis labels) is available. In real scenarios, this would be extracted from a corresponding label set, but for simplicity, we‚Äôll assume it‚Äôs already aligned with the rows of W_df.\n",
    "\n",
    "Then have the machine learning pipeline to use W_df for X, and we‚Äôll assume that y (labels) are provided or already available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae5725e",
   "metadata": {},
   "source": [
    "To feed these biomarkers into a prediction model, after applying NMF, the new features (from the matrix ùëä in the first code, which represent the samples' projections onto the NMF components) should be used as the input features for the machine learning model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9b7d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b442675",
   "metadata": {},
   "source": [
    "Data Preparation:<br>\n",
    "The dataset is loaded using pandas.<br>\n",
    "The target variable is separated from the features (X), and the dataset is split into training and testing sets using train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dcc0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming W_df from the first code is used as X (features)\n",
    "# Create some dummy labels for demonstration purposes (replace with actual labels)\n",
    "# Ensure the length of labels matches the number of rows in W_df\n",
    "y = pd.Series([1 if i % 2 == 0 else 0 for i in range(W_df.shape[0])], name='diagnosis')\n",
    "\n",
    "# Prepare the data\n",
    "X = W_df  # The matrix W_df (transformed features from NMF)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9179d6",
   "metadata": {},
   "source": [
    "Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e1ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b6ea6",
   "metadata": {},
   "source": [
    "A Random Forest Classifier model is trained on the training data (X_train and y_train)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e92f6",
   "metadata": {},
   "source": [
    "The n_estimators = 100 argument specifies the number of decision trees to train within the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75f2e759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b92497",
   "metadata": {},
   "source": [
    "Model Evaluation:<br>\n",
    "The trained model is then used to predict the class labels for the test set (X_test), and the predictions are compared with the true labels (y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83778219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83554939",
   "metadata": {},
   "source": [
    "The accuracy of the model is computed using accuracy_score, and a more detailed classification report (precision, recall, F1-score) is generated using classification_report.\n",
    "\n",
    "+ accuracy_score(y_test, y_pred): This calculates the overall accuracy of the model by comparing predicted values (y_pred) with actual values (y_test).\n",
    "+ classification_report(y_test, y_pred): This provides a more detailed performance evaluation, showing precision, recall, F1-score, and support for each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabd517",
   "metadata": {},
   "source": [
    "The output includes:\n",
    "1.\tAccuracy: The overall accuracy of the classifier (i.e., the percentage of correct predictions).\n",
    "2.\tClassification Report: A detailed breakdown of the model's performance:\n",
    "    + Precision: The proportion of true positives (correct disease predictions) among all predicted positives.\n",
    "    + Recall: The proportion of true positives among all actual positives (diseased samples).\n",
    "    + F1-score: The harmonic mean of precision and recall.\n",
    "    + Support: The number of samples in each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38877eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35714285714285715\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36         9\n",
      "           1       0.56      0.26      0.36        19\n",
      "\n",
      "    accuracy                           0.36        28\n",
      "   macro avg       0.41      0.41      0.36        28\n",
      "weighted avg       0.46      0.36      0.36        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1672c3",
   "metadata": {},
   "source": [
    "##### Limitations and Considerations:\n",
    "Choosing the Right k: The number of components must be selected carefully‚Äîtoo few can underrepresent complexity, too many can overfit.\n",
    "\n",
    "Noise Sensitivity: NMF can be sensitive to data quality; pre-processing steps are crucial.\n",
    "\n",
    "Validation: Biomarkers identified computationally should be experimentally validated or confirmed in independent datasets.\n",
    "\n",
    "Of course with adjustments, you can increase the accuracy via selected methods such as hyperparameter tuning or feature importance to identify the most influential features in predicting the disease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
